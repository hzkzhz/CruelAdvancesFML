- 冗余度和复杂性之间的关系公式化的结果：两变量之间的信息交互——

    - $MI[X,Y]=E_{f[x, y]}[\log \frac{f[x,y]}{f[x]f[y]}]=H[X]+H[Y]-H[X,Y]$.

- 体现了这两类之间如果进行区分会带来的信息增量。是非负的且对称点，为 0 当且仅当两个变量是独立的。

- 对于正态分布的变量，与皮尔逊相关系数有关系 $MI[X,Y]=-\frac{1}{2}\log[1-ρ^2]$.

- 因此是一种刻画变量间相关系数的自然方式，无论其相关关系是否是线性的。而广义的信息方差也是一个交互信息推导出来的指标。

#### 极大似然估计量

- 使用历史数据估计频率，进而依据频率估计熵的大小，最后一般会收敛，是一个熵的极大似然估计值，但看需要一个较大的样本量。