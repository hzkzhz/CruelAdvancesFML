#### 适应于更多的样本量

- 许多机器学习算法都不能适应于大量的样本量。例：支持向量机面对大量样本点训练时间较慢，而收敛结果未必全局最优，可能欠拟合。

- 一种解决方式是使用 Bagging，而其基础的预测器是不能很好扩展的类。在使用其时需要加入一严格的停止条件，如 SVM 中的 `max_iter`, `tol` 分别表示最大迭代次数和允许误差大小；RF 中的 `max_depth`, `min_weight_fraction_leaf`。提前停止会增加各个预测器输出的方差，但是多个平均又降低了这一方差。

- 由于可以并行 Bagging 把大样本的顺序任务转换为许多同时运行的较小任务。

- Bagging 可以对极大的数据集进行快速和稳健的预测。