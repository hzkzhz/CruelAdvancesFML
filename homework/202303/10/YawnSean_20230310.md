#### 随机森林

- 决策树本身容易发生过拟合，而提高预测的方差。为了解决这一问题，引入了随机森林使用聚合预测的方式降低方差。

- 随机森林与 Bagging 有相似性，都是独立训练各个预测模型，而使用又放回抽样的数据子集。差别在于随机森林又引入了新一层的随机性：当分裂节点的时候，只有一部分随机的子集在某个属性上被评估，为了降低预测器之间的相关系数。

- 除此之外，随机森林还可以衡量各个特征的重要性，也提供了包外预测准确性的估计（虽然金融数据中往往发生高估）。但随机森林不一定能比独立的决策树的偏差更小。

- 如果样本冗余问题过于严重，那么将会训练出一堆过拟合的树，不符合要求。

- 一些解决过拟合问题的方法：

    - 设置参数 `max_features` 使其数值较低，保证树间更可能不同。

    - 提前终止设定：`min_weight_fraction_leaf`，使得叶子节点有一定样本量。

    - 对 `DecisionTreeClassifier`/`RandomForestClassifier` 使用 `BaggingClassifier`，而 `max_samples` 保证样本之间的独特性。

    - 将采样方式变为序列随机采样。