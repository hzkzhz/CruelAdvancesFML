# notes

作者提到了一个之前学过但是没有学明白的概念 cross entropy loss。之前听说过这个概念大概是偏差程度的，可以当作 loss 函数。

在一些情况，只是看 accuracy 并不能非常好的反应模型的效果，我们希望我们能够以较大的概率得到我们想要的结果，确保赚钱的策略不是瞎猫碰上死耗子。

大概意思就是我们的分类任务往往最后给每个类别都会有一个分数，一般都会经过一下 softmax，最后这些分数的和就变成 1 了。这样的话如果一个类别的概率是 0.51 那它就获胜了，但是获胜的并不是很光彩，因为这说明模型对这个答案并不是很自信。所以我们使用 cross entropy，这样可以衡量出这个 “信心”