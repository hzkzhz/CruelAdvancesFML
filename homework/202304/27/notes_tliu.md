# notes

hyper parameter tuning

看起来这就是大家常说的 调参。

如果调参做的不好，可能会过拟合。实验室之前有个同学超参数调的时候用了训练集的数据，结果过拟合非常严重。

作者介绍了 grid search 格点搜索法，意思就是把所有的超参数构成的笛卡尔积里的元素都遍历一下。

使用这样的方法主要是想画出来一个实验效果和超参数之间的一个函数。格点法就类似于我们给函数的自变量取了很多的可能值，然后拟合一下这个函数。从这个角度看，超参数和实验效果之间的函数是不是也能机器学习（x

除了 grid search，也有 random search。这个在一些情况表现的更好，因为 grid 可能间距给的太大，导致我们错失了很多信息。