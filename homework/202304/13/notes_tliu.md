# notes

很多 PM 甚至一些有量化背景的人，都没有意识到 overfit 有多么容易发生。作者希望介绍一个在做 backtest 之前应该完成的一个分析，以此来确定是否是 overfit 的迹象。


我们希望能够找到对结果影响比较大的 feature，加强这些 feature；或者是找到对结果根本没什么影响的 feature，相当于就是一些 noise，把他们过滤掉。

这个任务本身肯定是困难的，这相当于要求我们能够解释这个模型。尤其是最终拟合出来的结果可能是非常复杂的，看似某个feature权重很大但是也不一定是有用的，比如 i 和 j 是两个相反的 feature，训练的时候完全可能 i 和 j 的权重是相反数。这样的话两个都很大（绝对值）但是其实都没有什么作用因为加起来就抵消了。

