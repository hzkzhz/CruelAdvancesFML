#### Bagging 分类器与独特性

- 对于一个大小为 $x$ 的集合中每次随机取一个，取 $x$ 次，则任意一个元素完全没有被取到的概率为 $(1-\frac{1}{x})^x$，在 $x$ 充分大的情况下接近 $\frac{1}{e}$ 。因此采样下的不同的观察为 $1-\frac{1}{e}$ 左右。

- 而假设最大的不重合结果为 $K$，则采样的不同观察为 $1-\frac{1}{e^\frac{K}{l}}$，带来了过度采样。

- 在每个观察的独特性均较低的情况下，则会在一次 Bagging 中的采样更可能产生冗余，也更与样本外观察相似。可能导致类似随机森林算法中给出同样过拟合的结果，带来效率损失。

- 一种解决方式：删去有重叠的结果（在采样前）。这样可能带来信息的大量损失。

- 另一种解决方式：使用平均的独特性。`sklearn.ensemble.BaggingClassifier` 接受 `max_samples` 的参数，将其设置为 `tW` 的均值（合理吗？如果真的都不发生重叠，则取的个数为全集，可能应当再乘以一个系数），这样采样频率就不会显著高于其独特性。而随机森林可以使用大量的决策树规避问题。